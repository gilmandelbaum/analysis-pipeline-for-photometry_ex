{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_set_generate_helper_functions as ghf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/anaconda3/bin/python3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path to import the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_import = \"/Volumes/GilInVivoPaper.large/2.Photometry_in_str/0.data_Sets/1.lateral_medial_6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path where to save it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save= \"/Volumes/GilInVivoPaper.large/2.Photometry_in_str/1.lateral_medial_6_analysis\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update depending on analysis: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_str = '0a1b2a3i4abcd5a6a7a'\n",
    "HowManyBack=1\n",
    "drop2blocks = \"yes\"\n",
    "drop2lastblocks = \"no\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folder to save the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderName=\"right_dual_color_photo_full_data_after_QC\" #folder where the plot data_set will be saved \n",
    "#folderName=\"left_dual_color_photo_full_data_set_after_inspection\" #folder where the plot data_set will be saved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/GilInVivoPaper.large/2.Photometry_in_str/1.lateral_medial_6_analysis/right_dual_color_photo_full_data_after_QC/0a1b2a3i4abcd5a6a7a'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_path_to_save = path_to_save+\"/\"+folderName+\"/\"+seq_str\n",
    "full_path_to_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import the data table: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name of xlsx file that has the sessions we want to run: \n",
    "MasterSheetName= '3.lateral_ medial_6_lateral_channels_final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mouse_Date_FileName = pd.read_excel(path_to_save+'/'+folderName+\"/\"+MasterSheetName+'.xlsx') #mdf is mouse data file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mouse</th>\n",
       "      <th>date</th>\n",
       "      <th>file name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T163</td>\n",
       "      <td>181207</td>\n",
       "      <td>T163-123432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T163</td>\n",
       "      <td>181128</td>\n",
       "      <td>T163-115220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T163</td>\n",
       "      <td>181203</td>\n",
       "      <td>T163-115901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T163</td>\n",
       "      <td>181130</td>\n",
       "      <td>T163-133215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T163</td>\n",
       "      <td>181204</td>\n",
       "      <td>T163-114628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>T202</td>\n",
       "      <td>190530</td>\n",
       "      <td>T202-152554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>T202</td>\n",
       "      <td>190522</td>\n",
       "      <td>T202-141516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>T202</td>\n",
       "      <td>190529</td>\n",
       "      <td>T202-160644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>T202</td>\n",
       "      <td>190526</td>\n",
       "      <td>T202-142728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>T202</td>\n",
       "      <td>190516</td>\n",
       "      <td>T202-165613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mouse    date    file name\n",
       "0   T163  181207  T163-123432\n",
       "1   T163  181128  T163-115220\n",
       "2   T163  181203  T163-115901\n",
       "3   T163  181130  T163-133215\n",
       "4   T163  181204  T163-114628\n",
       "..   ...     ...          ...\n",
       "70  T202  190530  T202-152554\n",
       "71  T202  190522  T202-141516\n",
       "72  T202  190529  T202-160644\n",
       "73  T202  190526  T202-142728\n",
       "74  T202  190516  T202-165613\n",
       "\n",
       "[75 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mouse_Date_FileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mouse_Date_FileName = Mouse_Date_FileName.iloc[0:45,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Mouse_Date_FileName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the full data structure for each session: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_object_data_lick(Mouse_Date_FileName,path):\n",
    "    data_lick_data_set = []\n",
    "    counter = 1 \n",
    "    \n",
    "    l_mouse = list(Mouse_Date_FileName[\"mouse\"]) \n",
    "    l_date_ = list(Mouse_Date_FileName.apply(lambda x: generate_date_(x[\"date\"]),axis=1))  \n",
    "    l_date_and_name = list(Mouse_Date_FileName.apply(lambda x: generate_name_and_date(x[\"date\"],x[\"mouse\"]),axis=1))\n",
    "    \n",
    "    numer_of_sessions_dataset = len(l_mouse)\n",
    "    \n",
    "    for (mouse, date_, date_and_name) in zip(l_mouse, l_date_, l_date_and_name):\n",
    "        print (\"session number\"+\" \"+str(counter)+\" \"+\"was imported (out of\"+\" \"+str(numer_of_sessions_dataset)+\")\")\n",
    "        data_lick = pd.read_excel(path+\"/\"+mouse+\"/\"+date_and_name+\"/\"+mouse+\"_dataLick_label.xlsx\")\n",
    "        data_lick_data_set.append(data_lick)  \n",
    "        counter +=1\n",
    "        \n",
    "    return (data_lick_data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_date_(Date):\n",
    "    return('20'+str(Date)[:2]+'_'+str(Date)[2:4]+'_'+str(Date)[4:6])\n",
    "\n",
    "def generate_name_and_date(Date,Mouse):\n",
    "    return ('20'+str(Date)[:2]+'_'+str(Date)[2:4]+'_'+str(Date)[4:6]+'__'+Mouse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session number 1 was imported (out of 75)\n",
      "session number 2 was imported (out of 75)\n",
      "session number 3 was imported (out of 75)\n",
      "session number 4 was imported (out of 75)\n",
      "session number 5 was imported (out of 75)\n",
      "session number 6 was imported (out of 75)\n",
      "session number 7 was imported (out of 75)\n",
      "session number 8 was imported (out of 75)\n",
      "session number 9 was imported (out of 75)\n",
      "session number 10 was imported (out of 75)\n",
      "session number 11 was imported (out of 75)\n",
      "session number 12 was imported (out of 75)\n",
      "session number 13 was imported (out of 75)\n",
      "session number 14 was imported (out of 75)\n",
      "session number 15 was imported (out of 75)\n",
      "session number 16 was imported (out of 75)\n",
      "session number 17 was imported (out of 75)\n",
      "session number 18 was imported (out of 75)\n",
      "session number 19 was imported (out of 75)\n",
      "session number 20 was imported (out of 75)\n",
      "session number 21 was imported (out of 75)\n",
      "session number 22 was imported (out of 75)\n",
      "session number 23 was imported (out of 75)\n",
      "session number 24 was imported (out of 75)\n",
      "session number 25 was imported (out of 75)\n",
      "session number 26 was imported (out of 75)\n",
      "session number 27 was imported (out of 75)\n",
      "session number 28 was imported (out of 75)\n",
      "session number 29 was imported (out of 75)\n",
      "session number 30 was imported (out of 75)\n",
      "session number 31 was imported (out of 75)\n",
      "session number 32 was imported (out of 75)\n",
      "session number 33 was imported (out of 75)\n",
      "session number 34 was imported (out of 75)\n",
      "session number 35 was imported (out of 75)\n",
      "session number 36 was imported (out of 75)\n",
      "session number 37 was imported (out of 75)\n",
      "session number 38 was imported (out of 75)\n",
      "session number 39 was imported (out of 75)\n",
      "session number 40 was imported (out of 75)\n",
      "session number 41 was imported (out of 75)\n",
      "session number 42 was imported (out of 75)\n",
      "session number 43 was imported (out of 75)\n",
      "session number 44 was imported (out of 75)\n",
      "session number 45 was imported (out of 75)\n",
      "session number 46 was imported (out of 75)\n",
      "session number 47 was imported (out of 75)\n",
      "session number 48 was imported (out of 75)\n",
      "session number 49 was imported (out of 75)\n",
      "session number 50 was imported (out of 75)\n",
      "session number 51 was imported (out of 75)\n",
      "session number 52 was imported (out of 75)\n",
      "session number 53 was imported (out of 75)\n",
      "session number 54 was imported (out of 75)\n",
      "session number 55 was imported (out of 75)\n",
      "session number 56 was imported (out of 75)\n",
      "session number 57 was imported (out of 75)\n",
      "session number 58 was imported (out of 75)\n",
      "session number 59 was imported (out of 75)\n",
      "session number 60 was imported (out of 75)\n",
      "session number 61 was imported (out of 75)\n",
      "session number 62 was imported (out of 75)\n",
      "session number 63 was imported (out of 75)\n",
      "session number 64 was imported (out of 75)\n",
      "session number 65 was imported (out of 75)\n",
      "session number 66 was imported (out of 75)\n",
      "session number 67 was imported (out of 75)\n",
      "session number 68 was imported (out of 75)\n",
      "session number 69 was imported (out of 75)\n",
      "session number 70 was imported (out of 75)\n",
      "session number 71 was imported (out of 75)\n",
      "session number 72 was imported (out of 75)\n",
      "session number 73 was imported (out of 75)\n",
      "session number 74 was imported (out of 75)\n",
      "session number 75 was imported (out of 75)\n",
      "CPU times: user 19.4 s, sys: 326 ms, total: 19.7 s\n",
      "Wall time: 20.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "behavior_data_lick_data_set = extract_data_object_data_lick(Mouse_Date_FileName,path_to_import)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract_data_object_data_lick(Mouse_Date_FileName,path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A function to help loop on each sessioon with various functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_looper(data_set,function):\n",
    "    organized_data_lick_list=[]\n",
    "    for session in data_set:\n",
    "        result = function(session)\n",
    "        organized_data_lick_list.append(result)\n",
    "    return organized_data_lick_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_behavior_data_lick (behavior_data_lick):        \n",
    "    if behavior_data_lick.columns.tolist() == ['iBlock', 'iTrial', 'iSpout', 'sTrial_start', 'sTrial_end', 'tState']:\n",
    "        pass\n",
    "    else:\n",
    "        #Shifting the names on the columns, so each column has the right label. (raw data has these labels shifted)\n",
    "        behavior_data_lick=behavior_data_lick.rename(columns={\"nTrial\": \"iBlock\", \"iBlock\":\"iTrial\", \n",
    "                                                              \"iTrial\":\"iSpout\",\"iSpout\":\"sTrial_start\", \n",
    "                                                              \"sTrial_start\":\"sTrial_end\", \"sTrial_end\":\"tState_new\"})\n",
    "        #I will delete the extra column\n",
    "        behavior_data_lick=behavior_data_lick.drop(\"tState\", 1)\n",
    "        behavior_data_lick=behavior_data_lick.rename(columns={\"tState_new\":\"tState\"})\n",
    "        \n",
    "    #this is to delete the first and last rows which have no lick data  \n",
    "    behavior_data_lick=behavior_data_lick[1: -1]\n",
    "    #Drop everything before first trial\n",
    "    behavior_data_lick= behavior_data_lick[behavior_data_lick.iBlock>0]\n",
    "    return behavior_data_lick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add nTrial to dataLick\n",
    "def get_nTrial_DataLick_list(session):\n",
    "    \n",
    "    block=1\n",
    "    nTrial= 0\n",
    "    l=[]\n",
    "    \n",
    "    for row in session.iterrows(): \n",
    "        \n",
    "        (iblock, iTrial)= (row[1][\"iBlock\"], row[1][\"iTrial\"])\n",
    "        \n",
    "        if iblock!=block:\n",
    "            block+=1\n",
    "            nTrial+=(iTrial)\n",
    "            l.append((nTrial))\n",
    "            \n",
    "        else:\n",
    "            if iTrial>nTrial:\n",
    "                nTrial+=(iTrial-nTrial)\n",
    "                l.append((nTrial))\n",
    "            elif iTrial<nTrial:\n",
    "                nTrial+= iTrial - (session.at[row[0]-1, \"iTrial\"])\n",
    "                l.append((nTrial))\n",
    "            else:\n",
    "                l.append((nTrial))\n",
    "                \n",
    "    session[\"nTrial\"]= l\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_data_lick_data_set_clean = session_looper (behavior_data_lick_data_set,clean_behavior_data_lick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 Âµs, sys: 0 ns, total: 2 Âµs\n",
      "Wall time: 5.96 Âµs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "behavior_data_lick_data_set_clean = session_looper (behavior_data_lick_data_set_clean,get_nTrial_DataLick_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_first_two_blocks(behavior_data_lick):\n",
    "    if drop2blocks==\"yes\":\n",
    "        behavior_data_lick = behavior_data_lick[behavior_data_lick['iBlock'] > 2]\n",
    "    \n",
    "    if drop2lastblocks==\"yes\":\n",
    "        lastblock = behavior_data_lick['iBlock'].values.tolist()[-1]\n",
    "        SecondToLast = lastblock-1\n",
    "        behavior_data_lick = behavior_data_lick[behavior_data_lick.iBlock<SecondToLast]\n",
    "\n",
    "    return behavior_data_lick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_data_lick_data_set_clean = session_looper (behavior_data_lick_data_set_clean,drop_first_two_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#behavior_data_lick_data_set_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = behavior_data_lick_data_set_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_set[0].to_csv(\"sample_data_lick_pickle.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/GilInVivoPaper.large/2.Photometry_in_str/1.lateral_medial_6_analysis/right_dual_color_photo_full_data_after_QC/0a1b2a3i4abcd5a6a7a/data_object_data_lick_0a1b2a3i4abcd5a6a7a.pickle\n",
      "CPU times: user 14.9 ms, sys: 15.5 ms, total: 30.4 ms\n",
      "Wall time: 271 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "root = Path(full_path_to_save)\n",
    "d = \"data_object_data_lick\"+\"_\"+seq_str+'.pickle'\n",
    "my_path = root / d \n",
    "print (my_path)\n",
    "my_file = open(my_path, 'wb')\n",
    "my_file = pickle.dump((data_set),my_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
